{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "Let's load the provided data into some pandas dataframs and gather some basic information about each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print some information about each our files\n",
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data successfully loaded\n",
    "\n",
    "We've now got a peek of each of our DataFrames which have been read in. Let's gather some exploratory information about the breakdown for a few of the stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_unavailable = sum(pd.isnull(profile['income']))\n",
    "print('Income reported: ', len(profile) - income_unavailable)\n",
    "print('Income unreported: ', income_unavailable)\n",
    "\n",
    "clean_profile = profile.dropna(axis=0)\n",
    "column_name = 'income'\n",
    "\n",
    "# Lets see an income breakdown and plot it\n",
    "ax=plt.subplots(figsize=(6,3))\n",
    "# get data by column_name and display a histogram\n",
    "ax = plt.hist(clean_profile[column_name], bins=30)\n",
    "title=f'Histogram of {column_name} among reporters'\n",
    "plt.title(title, fontsize=12)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see our gender breakdown\n",
    "print('Total: ', len(profile))\n",
    "print('Women: ', len(profile[profile['gender'] == 'F']))     \n",
    "print('Men: ', len(profile[profile['gender'] == 'M']))\n",
    "print('Other: ', len(profile[profile['gender'] == 'O']))\n",
    "print('None: ', sum(pd.isnull(profile['gender'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what type events are available\n",
    "types = transcript.event.unique()\n",
    "for event in types:\n",
    "    print(event, '    \\t:\\t', len(transcript[transcript['event'] == event]))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about how to proceed with data pre-processing\n",
    "\n",
    "At this point, we're ready to start transforming our data in order to maximize the amount of usefulness we'll gain from performing the Principal Component Analysis.\n",
    "\n",
    "Something we want to be able to continue to referenece is the need for our data to be kept within terms of each customer. In order to do that, we'll have to make some modifications to the profile dataFrame and include various statistics derived from the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_stats_df(df):\n",
    "    # make a new copy of the profile dataframe\n",
    "    new_df = df\n",
    "    types = transcript.event.unique()         \n",
    "    \n",
    "    event_count_map = { 'offer received': [],\n",
    "                        'offer viewed': [],\n",
    "                        'transaction': [],\n",
    "                        'offer completed': [] }\n",
    "    \n",
    "    # Let's take a count of each user's records for each event type\n",
    "    for index, row in new_df.iterrows():    \n",
    "        pid = row['id']\n",
    "        user_events = transcript[transcript['person'] == pid]\n",
    "    \n",
    "        for event in types:\n",
    "            # Add the new column with the calculated values for each event type\n",
    "            event_count_map[event].append(len(user_events[user_events['event'] == event]))\n",
    "    \n",
    "    # Now add each column based on the results above\n",
    "    new_df['received'] = event_count_map['offer received']\n",
    "    new_df['viewed'] = event_count_map['offer viewed']\n",
    "    new_df['transactions'] = event_count_map['transaction']\n",
    "    new_df['completed'] = event_count_map['offer completed']\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result = user_stats_df(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result))\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# 1) Convert membership date to age\n",
    "\n",
    "# 2) need an offer df? columns: id, person, number_of views, initial_time_to_view, time_to_complete\n",
    "#    avg_response_time add a column for avg offer age when viewed (time(viewed) - time(recieved))\n",
    "#    avg_completion_time for avg offer age when completed (time(completed) - time(viewed))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
